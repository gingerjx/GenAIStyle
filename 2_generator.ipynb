{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "Notebook uses Large Language Models to generate the text for 10 authors from `res/selected/author_list` file. It uses the list of queries from `res/queries` and the system specification message that together create the prompt. The goal is to generate text in writing style of the specific author, where the topic is of secondary importance. Results are saved in `res` directory.\n",
    "\n",
    "In order to run the notebook create `.env` file in the root of the project and set the api keys in the following manner:\n",
    "\n",
    "```bash\n",
    "ANTHROPIC_API_KEY=YOUR_API_KEY\n",
    "GOOGLE_API_KEY=YOUR_API_KEY\n",
    "MISTRAL_API_KEY=YOUR_API_KEY\n",
    "OPENAI_API_KEY=YOUR_API_KEY\n",
    "```\n",
    "\n",
    "Below there is a list of used LLMs along with their default settings that are used. The intention is to give the LLM the freedom, without many constraints, in generation process. Default settings provide sufficient level of such flexibility to the model.\n",
    "\n",
    "### OpenAI defaults\n",
    "\n",
    "[07.06.2024] [Reference](https://platform.openai.com/docs/api-reference/chat)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"seed\": null,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1.0,\n",
    "  \"frequency_penalty\": 0.0,\n",
    "  \"presence_penalty\": 0.0,\n",
    "  \"n\": 1,\n",
    "  \"stop\": null,\n",
    "  \"echo\": false,\n",
    "  \"best_of\": 1,\n",
    "}\n",
    "```\n",
    "\n",
    "### Gemini defaults\n",
    "\n",
    "[07.06.2024] [Reference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#request_body)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"temperature\": 1.0,\n",
    "  \"topK\": 32,\n",
    "  \"topP\": 1,\n",
    "  \"frequencyPenalty\": 0,\n",
    "  \"presencePenalty\": 0,\n",
    "  \"stopSequences\": null,\n",
    "}\n",
    "```\n",
    "\n",
    "### MistralAI defaults\n",
    "\n",
    "[07.06.2024] [Reference](https://docs.mistral.ai/api/#operation/createChatCompletion)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 1,\n",
    "  \"random_seed\": null\n",
    "}\n",
    "```\n",
    "### Anthropic defaults\n",
    "\n",
    "[07.06.2024] [Reference](https://docs.anthropic.com/en/api/messages)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"stop_sequences\": null,\n",
    "  \"temperature\": 1.0,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = Secrets()\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"gpt-3.5-turbo-0125\": ChatOpenAI(model=\"gpt-3.5-turbo-0125\"),\n",
    "    \"gpt-4o\": ChatOpenAI(model=\"gpt-4o\", api_key=secrets.openai_api_key),\n",
    "    \"gemini-1.5-flash\": ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=secrets.google_api_key),\n",
    "    \"open-mixtral-8x7b\": ChatMistralAI(model=\"open-mixtral-8x7b\", api_key=secrets.mistral_api_key),\n",
    "    \"claude-3-haiku-20240307\": ChatAnthropic(model=\"claude-3-haiku-20240307\", api_key=secrets.anthropic_api_key),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = TextGenerator(\n",
    "    models=models,\n",
    "    queries_path=settings.paths.ws_query_filepath,\n",
    "    authors_path=settings.paths.ws_selected_authors_filepath,\n",
    "    res_directory=settings.paths.res_dir,\n",
    "    response_number_of_words=settings.configuration.ws_response_number_of_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Generating [claude-3-haiku-20240307]-[Mark Twain] Describe the most peculiar meal you've ever encountered.\n"
     ]
    }
   ],
   "source": [
    "generated_texts, unprocessed_requests = text_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
