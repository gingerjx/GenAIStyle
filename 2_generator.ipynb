{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "Notebook uses Large Language Models to generate the text for ten authors from selected in `1_writing_style_authors_selection.ipynb` notebook. It uses the list of queries from and the system specification message that together create the prompt. The goal is to generate text in writing style of the specific author, where the topic is of secondary importance.\n",
    "\n",
    "In order to run the notebook create `.env` file in the root of the project and set the api keys in the following manner:\n",
    "\n",
    "```bash\n",
    "ANTHROPIC_API_KEY=YOUR_API_KEY\n",
    "GOOGLE_API_KEY=YOUR_API_KEY\n",
    "MISTRAL_API_KEY=YOUR_API_KEY\n",
    "OPENAI_API_KEY=YOUR_API_KEY\n",
    "```\n",
    "\n",
    "Below there is a list of used LLMs along with their default settings that are used. The intention is to give the LLM the freedom, without many constraints, in generation process. Default settings provide sufficient level of such flexibility to the model.\n",
    "\n",
    "- [OpenAI](https://platform.openai.com/docs/api-reference/chat)\n",
    "\n",
    "- [Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#request_body)\n",
    "\n",
    "- [MistralAI](https://docs.mistral.ai/api/#operation/createChatCompletion)\n",
    "\n",
    "- [Anthropic](https://docs.anthropic.com/en/api/messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = Secrets()\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"gpt-3.5-turbo-0125\": ChatOpenAI(model=\"gpt-3.5-turbo-0125\"),\n",
    "    \"gpt-4o\": ChatOpenAI(model=\"gpt-4o\", api_key=secrets.openai_api_key),\n",
    "    \"gemini-1.5-flash\": ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=secrets.google_api_key),\n",
    "    \"open-mixtral-8x7b\": ChatMistralAI(model=\"open-mixtral-8x7b\", api_key=secrets.mistral_api_key),\n",
    "    \"claude-3-haiku-20240307\": ChatAnthropic(model=\"claude-3-haiku-20240307\", api_key=secrets.anthropic_api_key),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = TextGenerator(\n",
    "    models=models,\n",
    "    queries_path=settings.paths.ws_query_filepath,\n",
    "    authors_path=settings.paths.ws_selected_authors_filepath,\n",
    "    res_directory=settings.paths.res_dir,\n",
    "    response_number_of_words=settings.configuration.ws_response_number_of_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts, unprocessed_requests = text_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
